{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1724304e",
   "metadata": {},
   "source": [
    "Conformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9b200b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "from torchaudio.transforms import MelSpectrogram, Resample\n",
    "import pandas as pd\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, target_length=73):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.file_paths = self.data['file_path'].tolist()\n",
    "        self.labels = self.data['label'].tolist()\n",
    "        self.transform = transform\n",
    "        self.target_length = target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_file = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "\n",
    "        target_sample_rate = 16000\n",
    "        if sample_rate != target_sample_rate:\n",
    "            waveform = Resample(sample_rate, target_sample_rate)(waveform)\n",
    "\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "\n",
    "        if waveform.size(-1) < self.target_length:\n",
    "            pad_length = self.target_length - waveform.size(-1)\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, pad_length))\n",
    "        elif waveform.size(-1) > self.target_length:\n",
    "            waveform = waveform[:, :, :self.target_length]\n",
    "        \n",
    "        label = torch.tensor(label)  # Convert label to tensor here\n",
    "        return waveform, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45912ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MS24-1\\Environments\\environments\\speech_recognition\\lib\\site-packages\\torchaudio\\functional\\functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (512) may be set too high. Or, the value for `n_freqs` (513) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "\n",
    "transform = MelSpectrogram(sample_rate=16000, n_mels=512, hop_length=512, n_fft=1024)\n",
    "\n",
    "dataset = AudioDataset(\"labeled_data.csv\", transform=transform, target_length=73)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.1, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "#25m 0.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d99fa26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout=0.3):\n",
    "        super(ConformerBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=4, batch_first=True)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm3 = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv block\n",
    "        residual = x\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.norm1(x + residual)\n",
    "\n",
    "        # Self-attention block\n",
    "        residual = x\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "\n",
    "        # Feedforward block\n",
    "        residual = x\n",
    "        ff_output = self.ffn(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "\n",
    "        return x\n",
    "\n",
    "class ConformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, num_blocks=8, hidden_dim=384, dropout=0.3):\n",
    "        super(ConformerModel, self).__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        self.conformer_blocks = nn.ModuleList([\n",
    "            ConformerBlock(hidden_dim, dropout) for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.global_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # (B, T, input_dim)\n",
    "        x = self.input_proj(x)\n",
    "        for block in self.conformer_blocks:\n",
    "            x = block(x)\n",
    "        x = self.global_norm(x)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        return self.fc_out(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60f6823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "        elif val_score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b285dca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.1990, Train Acc: 50.17%, Val Loss: 1.1425, Val Acc: 53.83%\n",
      "Saved new best model!\n",
      "Epoch 2/20, Loss: 1.0029, Train Acc: 59.15%, Val Loss: 0.9830, Val Acc: 61.44%\n",
      "Saved new best model!\n",
      "Epoch 3/20, Loss: 0.8438, Train Acc: 66.81%, Val Loss: 0.7927, Val Acc: 68.57%\n",
      "Saved new best model!\n",
      "Epoch 4/20, Loss: 0.6792, Train Acc: 73.71%, Val Loss: 0.7016, Val Acc: 74.12%\n",
      "Saved new best model!\n",
      "Epoch 5/20, Loss: 0.5316, Train Acc: 80.08%, Val Loss: 0.6479, Val Acc: 76.75%\n",
      "Saved new best model!\n",
      "Epoch 6/20, Loss: 0.4215, Train Acc: 84.56%, Val Loss: 0.6051, Val Acc: 78.29%\n",
      "Saved new best model!\n",
      "Epoch 7/20, Loss: 0.3333, Train Acc: 87.95%, Val Loss: 0.5795, Val Acc: 80.80%\n",
      "Saved new best model!\n",
      "Epoch 8/20, Loss: 0.2647, Train Acc: 90.47%, Val Loss: 0.6719, Val Acc: 81.94%\n",
      "Saved new best model!\n",
      "Epoch 9/20, Loss: 0.2235, Train Acc: 92.26%, Val Loss: 0.6592, Val Acc: 81.49%\n",
      "Epoch 10/20, Loss: 0.1952, Train Acc: 93.16%, Val Loss: 0.6904, Val Acc: 81.65%\n",
      "Epoch 11/20, Loss: 0.1594, Train Acc: 94.49%, Val Loss: 0.7011, Val Acc: 82.71%\n",
      "Saved new best model!\n",
      "Epoch 12/20, Loss: 0.1441, Train Acc: 95.06%, Val Loss: 0.7108, Val Acc: 82.30%\n",
      "Epoch 13/20, Loss: 0.1328, Train Acc: 95.35%, Val Loss: 0.7793, Val Acc: 81.45%\n",
      "Epoch 14/20, Loss: 0.1270, Train Acc: 95.66%, Val Loss: 0.7189, Val Acc: 82.99%\n",
      "Saved new best model!\n",
      "Epoch 15/20, Loss: 0.1055, Train Acc: 96.37%, Val Loss: 0.8063, Val Acc: 82.50%\n",
      "Epoch 16/20, Loss: 0.0996, Train Acc: 96.71%, Val Loss: 0.7567, Val Acc: 82.50%\n",
      "Epoch 17/20, Loss: 0.0939, Train Acc: 96.79%, Val Loss: 0.8345, Val Acc: 82.83%\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConformerModel(input_dim=512, num_classes=5).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    for mel_spectrograms, labels in train_loader:\n",
    "        mel_spectrograms = mel_spectrograms.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        mel_spectrograms = mel_spectrograms.squeeze(1)\n",
    "        logits = model(mel_spectrograms)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "        total_preds += labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct_preds / total_preds * 100\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spectrograms, labels in val_loader:\n",
    "            mel_spectrograms = mel_spectrograms.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            mel_spectrograms = mel_spectrograms.squeeze(1)\n",
    "            logits = model(mel_spectrograms)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "    \n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = correct_preds / total_preds * 100\n",
    "    return avg_loss, accuracy\n",
    "EPOCHS = 20\n",
    "best_val_acc = 0.0\n",
    "\n",
    "early_stopper = EarlyStopping(patience=3, min_delta=0.001)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loss, train_acc = train(model, train_loader, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model_Conformer_Crema.pth\")\n",
    "        print(\"Saved new best model!\")\n",
    "    \n",
    "    early_stopper(val_acc)\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "#1033m 36.1s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53efba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spectrograms, labels in test_loader:\n",
    "            mel_spectrograms = mel_spectrograms.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            mel_spectrograms = mel_spectrograms.squeeze(1) \n",
    "            logits = model(mel_spectrograms)\n",
    "\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = correct_preds / total_preds * 100\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro') * 100\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    return accuracy, f1, cm\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model_Conformer_Crema.pth\"))\n",
    "accuracy, f1, cm = evaluate(model, test_loader, device)\n",
    "\n",
    "\n",
    "#7m 0.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "060332ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 82.17%\n",
      "F1 Score: 82.10%\n",
      "Confusion Matrix:\n",
      "                Predicted angry  Predicted happy  Predicted neutral  \\\n",
      "Actual angry               1110               16                 90   \n",
      "Actual happy                 47              956                106   \n",
      "Actual neutral               88               42               1064   \n",
      "Actual sad                   39               25                 58   \n",
      "Actual fear                  14               96                 19   \n",
      "\n",
      "                Predicted sad  Predicted fear  \n",
      "Actual angry               28               4  \n",
      "Actual happy               64             110  \n",
      "Actual neutral             43              28  \n",
      "Actual sad                902              60  \n",
      "Actual fear               123            1039  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"F1 Score: {f1:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "label_names = ['angry', 'happy', 'neutral', 'sad', 'fear']\n",
    "cm_df = pd.DataFrame(cm, \n",
    "    index=[f\"Actual {label}\" for label in label_names],\n",
    "    columns=[f\"Predicted {label}\" for label in label_names])\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
